# 问题汇总

[TOC]

### 问题1

安装启动 kylin 时报出现 `Please make sure the user has the privilege to run hbase shell`

没有在 `/etc/profile` 中配置 HBASE_HOME 环境变量


### 问题2

在构建 cube 时，出现 `org.apache.kylin.engine.mr.exception.MapReduceException: Exception: java.net.ConnectException: Call From dxt102/192.168.1.102 to 0.0.0.0:10020 failed on connection exception: java.net.ConnectException: 拒绝连接`。

说明未启动 `JobHistoryServer`，执行 `$HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver` 启动。

### 问题3

在构建 cube 时，进度卡在 60% 多，报错，查看日志出现 `ERROR [main] org.apache.kylin.engine.mr.KylinReducer:java.lang.NoSuchMethodError: org.apache.hadoop.fs.FileSystem.setStoragePolicy(Lorg/apache/hadoop/fs/Path;Ljava/lang/String;)V`。

最后使用的版本是kylin3.1.3、hadoop2.7.3、hbase1.7.1、hive2.3.9

将 hbase 版本改为 1.6.0 就没有出现这个错误，执行成功。

参考这个链接：[https://issues.apache.org/jira/browse/KYLIN-5107](https://issues.apache.org/jira/browse/KYLIN-5107)

在测试样例和测试计算留存率构建 cube 时，又出现了这个问题。

将 kylin 版本改成 2.5.0，没有出现这个错误，但出现 `mr.exception.MapReduceException: no counters for job job_1642574471995_0010`

【TODO】

使用 docker 运行可以成功运行。

刚入门最好使用 docker 运行 kylin，这样可以避免很多环境问题。

### 问题4

在构建 cube 时，出现 `Error: java.io.IOException: java.lang.reflect.InvocationTargetException` `Caused by: java.io.EOFException: Premature EOF from inputStream`

因为在 hadoop 中设置了中间结果和输出结果启用压缩，在 hive 中未设置。

可以在 hive 中启用，或者删除 hadoop 中关于启用压缩的配置。

```xml
<!-- hive-site.xml -->
<!-- 添加如下配置，把lzo jar包放到lib下-->
<property>
   <name>hive.exec.compress.intermediate</name>
   <value>true</value>
</property>
<property>
   <name>hive.intermediate.compression.codec</name>
   <value>com.hadoop.compression.lzo.LzopCodec</value>
</property>
<property>
   <name>hive.intermediate.compression.type</name>
   <value>BLOCK</value>
</property>
<property>
  <name>hive.exec.compress.output</name>
  <value>true</value>
</property>
<property>
   <name>mapreduce.output.fileoutputformat.compress</name>
   <value>true</value>
</property>
<property>
   <name>mapreduce.output.fileoutputformat.compress.codec</name>
   <value>com.hadoop.compression.lzo.LzopCodec</value>
</property>
<property>
   <name>mapreduce.output.fileoutputformat.compress.type</name>
   <value>BLOCK</value>
</property>
```

### 问题5

在使用 spark 引擎构建 cube 时，出现 `Caused by: java.lang.IllegalArgumentException: Compression codec com.hadoop.compression.lzo.LzoCodec not found.`

在 hadoop 中配置了 lzo，所以当使用 yarn 模式时，spark 自身没有 lzo 的 jar 包所以无法找到。这是因为在 hadoop 的 core-site.xml 和 mapred-site.xml 中开启了压缩，并且压缩是 lzo 的。这就导致写入上传到 hdfs 的文件自动被压缩为 lzo 了。而 spark 没有 lzo 这个 jar 包，所以无法被找到。

解决方法很简单：

	ln -s  /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-lzo-0.4.20.jar /opt/module/spark-2.1.1-bin-hadoop2.7/jars/hadoop-lzo-0.4.20.jar

软连接过去就可以了。

或者配置 spark-default.conf 如下即可：

	spark.jars=/opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-lzo-0.4.20.jar

原文链接：[https://blog.csdn.net/Lcumin/article/details/113096793](https://blog.csdn.net/Lcumin/article/details/113096793)

### 问题6

启动时，出现 `Failed to find metadata store by url: kylin_metadata@hbase`

需要在mysql下创建 kylin 元数据库，并在 kylin.properties 中做如下配置：

```
kylin.metadata.url=kylin_metadata@jdbc,driverClassName=com.mysql.cj.jdbc.Driver,url=jdbc:mysql://bigdata101:3306/kylin,username=root,password=root
kylin.env.zookeeper-connect-string=localhost
```

将 mysql jdbc connector 放在 $KYLIN_HOME/ext 目录